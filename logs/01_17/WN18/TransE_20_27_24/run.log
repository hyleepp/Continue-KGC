2023-27-17 20:27:24 INFO     Saving logs in logs/01_17/WN18/TransE_20_27_24
2023-27-17 20:27:24 INFO     active_num = 1000
2023-27-17 20:27:24 INFO     batch_size = 500
2023-27-17 20:27:24 INFO     counter = 10
2023-27-17 20:27:24 INFO     dataset = WN18
2023-27-17 20:27:24 INFO     debug = False
2023-27-17 20:27:24 INFO     device = cuda
2023-27-17 20:27:24 INFO     dyn_scale = False
2023-27-17 20:27:24 INFO     expected_completion_ratio = 0.99
2023-27-17 20:27:24 INFO     hidden_size = 200
2023-27-17 20:27:24 INFO     incremental_learning_method = finetune
2023-27-17 20:27:24 INFO     incremental_learning_rate = 0.001
2023-27-17 20:27:24 INFO     init_scale = 0.001
2023-27-17 20:27:24 INFO     max_epochs = 10
2023-27-17 20:27:24 INFO     model = TransE
2023-27-17 20:27:24 INFO     n_ent = 40943
2023-27-17 20:27:24 INFO     n_rel = 18
2023-27-17 20:27:24 INFO     neg_size = -1
2023-27-17 20:27:24 INFO     optimizer = Adam
2023-27-17 20:27:24 INFO     patient = 10
2023-27-17 20:27:24 INFO     pretrain_learning_rate = 0.001
2023-27-17 20:27:24 INFO     pretrained_model_id = None
2023-27-17 20:27:24 INFO     reg_weight = 0
2023-27-17 20:27:24 INFO     regularizer = F2
2023-27-17 20:27:24 INFO     save_dir = logs/01_17/WN18/TransE_20_27_24
2023-27-17 20:27:24 INFO     setting = active_learning
2023-27-17 20:27:24 INFO     sta_scale = 1
2023-27-17 20:27:24 INFO     train_ratio = 0.9
2023-27-17 20:27:24 INFO     valid_period = 5
2023-27-17 20:27:24 INFO     	 Loading WN18 in active_learning setting, with shape (40943, 18)
2023-27-17 20:27:26 INFO     Total number of parameters 8195800
2023-27-17 20:27:26 INFO     	 Do not specific a pretraiend model, then training from scratch.
2023-27-17 20:27:26 INFO     	 Start pretraining phase 1: on training split.
2023-27-17 20:27:30 INFO     	 Epoch 0 | average train loss: 10.0210
2023-27-17 20:27:30 INFO     	 Epoch 0 | average valid loss: 18.0521
2023-27-17 20:27:34 INFO     	 Epoch 1 | average train loss: 8.0664
2023-27-17 20:27:34 INFO     	 Epoch 1 | average valid loss: 15.0762
2023-27-17 20:27:38 INFO     	 Epoch 2 | average train loss: 5.9390
2023-27-17 20:27:38 INFO     	 Epoch 2 | average valid loss: 11.3005
2023-27-17 20:27:42 INFO     	 Epoch 3 | average train loss: 3.9154
2023-27-17 20:27:42 INFO     	 Epoch 3 | average valid loss: 8.8302
2023-27-17 20:27:45 INFO     	 Epoch 4 | average train loss: 2.9911
2023-27-17 20:27:45 INFO     	 Epoch 4 | average valid loss: 7.8245
2023-27-17 20:27:47 INFO     MRR: 0.354, Hits@1: 0.220, Hits@3: 0.419, Hits@10: 0.621 
2023-27-17 20:27:47 INFO     Best results updated, save current model.
2023-27-17 20:27:51 INFO     	 Epoch 5 | average train loss: 2.5876
2023-27-17 20:27:51 INFO     	 Epoch 5 | average valid loss: 7.2753
2023-27-17 20:27:54 INFO     	 Epoch 6 | average train loss: 2.3427
2023-27-17 20:27:55 INFO     	 Epoch 6 | average valid loss: 6.9382
2023-27-17 20:27:58 INFO     	 Epoch 7 | average train loss: 2.1701
2023-27-17 20:27:58 INFO     	 Epoch 7 | average valid loss: 6.7120
2023-28-17 20:28:02 INFO     	 Epoch 8 | average train loss: 2.0450
2023-28-17 20:28:02 INFO     	 Epoch 8 | average valid loss: 6.5411
2023-28-17 20:28:06 INFO     	 Epoch 9 | average train loss: 1.9490
2023-28-17 20:28:06 INFO     	 Epoch 9 | average valid loss: 6.3980
2023-28-17 20:28:08 INFO     MRR: 0.390, Hits@1: 0.265, Hits@3: 0.449, Hits@10: 0.640 
2023-28-17 20:28:08 INFO     Best results updated, save current model.
2023-28-17 20:28:08 INFO     	 Pretrain phase 1 finished Optimization finished, get the best training epoch
2023-28-17 20:28:08 INFO     	 Start the pretrain phase 2: both train and valid data
