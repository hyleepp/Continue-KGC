2023-05-16 10:05:06 INFO     Saving logs in logs/01_16/WN18/TransE_10_05_06
2023-05-16 10:05:06 INFO     active_num = 1000
2023-05-16 10:05:06 INFO     batch_size = 500
2023-05-16 10:05:06 INFO     counter = 10
2023-05-16 10:05:06 INFO     dataset = WN18
2023-05-16 10:05:06 INFO     debug = False
2023-05-16 10:05:06 INFO     device = cuda
2023-05-16 10:05:06 INFO     dyn_scale = False
2023-05-16 10:05:06 INFO     expected_completion_ratio = 0.99
2023-05-16 10:05:06 INFO     hidden_size = 200
2023-05-16 10:05:06 INFO     incremental_learning_rate = 0.001
2023-05-16 10:05:06 INFO     init_scale = 0.001
2023-05-16 10:05:06 INFO     max_epochs = 200
2023-05-16 10:05:06 INFO     model = TransE
2023-05-16 10:05:06 INFO     n_ent = 40943
2023-05-16 10:05:06 INFO     n_rel = 18
2023-05-16 10:05:06 INFO     neg_size = -1
2023-05-16 10:05:06 INFO     optimizer = Adam
2023-05-16 10:05:06 INFO     patient = 10
2023-05-16 10:05:06 INFO     pretrain_learning_rate = 0.001
2023-05-16 10:05:06 INFO     pretrained_model_id = None
2023-05-16 10:05:06 INFO     reg_weight = 0
2023-05-16 10:05:06 INFO     regularizer = F2
2023-05-16 10:05:06 INFO     save_dir = logs/01_16/WN18/TransE_10_05_06
2023-05-16 10:05:06 INFO     setting = active_learning
2023-05-16 10:05:06 INFO     sta_scale = 1
2023-05-16 10:05:06 INFO     train_ratio = 0.9
2023-05-16 10:05:06 INFO     valid_period = 5
2023-05-16 10:05:06 INFO     	 Loading WN18 in active_learning setting, with shape (40943, 18)
2023-05-16 10:05:15 INFO     Total number of parameters 8192200
2023-05-16 10:05:15 INFO     	 Do not specific a pretraiend model, then training from scratch.
2023-05-16 10:05:15 INFO     	 Start pretraining phase 1: on training split.
